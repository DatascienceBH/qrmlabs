---
title: 'Lab Five: Inference for Two Populations'
author:
 - Alex Davis
 - Cody Adams
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#setwd("~/Methods Labs")
ds <- read.csv("Class Data Set Factored.csv")
library(ggplot2)
library(psych)
library(car)
library(vcd)
options(scipen = 999)
```

This lab covers the basics of inference for two populations. We'll go through proportions and cross tabulations; the different types of two sample t-tests; difference in one and two tailed tests; and how to plot means and the differences between means. The following packages are required for this lab: 

1. ggplot2
2. psych
3. car
4. vcd

## Part I: Proportions

To start with proportions, We will use the _glbcc_ variable from the class dataset that contains respondents' opinions on global climate change. We start with describing the data. A zero indicates "no" and 1 indicates "yes."

```{r prop, echo=TRUE}
t.gcc <- table(ds$glbcc)
t.gcc
```

Now we can describe the population proportions. To do this we use the _prop.table()_ function. We will specify the _prop.table()_ function to round to 4 decimals.

```{r prop2, echo=TRUE}
p.t.gcc <- round(prop.table(t.gcc), 4)
p.t.gcc 
```

The _prop.table()_ function describes the proportions of the population that believe humans cause climate change. Let's visualize the proportions. 

__Note:__ This lab introduces the _ggplots_ package, which will be used for visualizations moving forward. The _ggplot_ package includes various methods of visualizing data beyond the base visualization functions provided by R.

Data frames are required for ggplot visualizations, which can be constructed from the tables using the _data.frame()_ and _c()_ functions. The following is an example method of creating a data frame manually with values from the previous tables.

```{r prop3, echo=TRUE}
p.t.gcc
df <- data.frame(answer = c("0","1"), glbcc = c("0.4287", "0.5713"))
ggplot(df, aes(x=answer, y=glbcc)) +
  geom_bar(stat = "identity") 
```

As we learned in the last lab, there are uncertainties associated to point estimates. We can include confidence intervals to get a range of values for which we are confident (at some level) the value actually falls between. To calculate confidence intervals we need to find the standard error of the proportionn and assign it to an object that we will name _se_.

```{r prop4, echo=TRUE}
se <-sqrt((0.5713*(1-0.5713)/2547)) 
se
```

Alternatively, we can use the _describe()_ function to avoid rounding errors:

```{r prop5, echo=TRUE}
se <- describe(ds$glbcc)$se
se
```

With the standard error object, we can calculate the confidence intervals. Here we will calculate the following: the upper bounds and lower bounds for the yes and no confidence intervals.

$$CI=\hat{p} \pm z\frac{s}{\sqrt{n}},$$

Where $\hat{p}$ is the sample proportion. Recall that 95% confidence corresponds to a 1.96 z-score.

The proportion table provides the values we will use:

```{r prop6, echo=TRUE}
p.t.gcc
```

We assign these values to a _no_ and _yes_ object:

```{r prop7, echo=TRUE}
no <- 0.4287
yes <- 0.5713
```

Next we will calculate the confidence intervals:

```{r prop8, echo=TRUE}
no.up <- no + 1.96 * se
no.low <- no - 1.96 * se
yes.up <- yes + 1.96 * se
yes.low <- yes - 1.96 * se

```

For simplicity in creating a data frame, we can use the previously created objects. 

```{r prop9, echo=TRUE}
df <- data.frame(answer = c("0", "1"), glbcc = c(no,yes), lower = c(no.low,yes.low),
                 upper = c(no.up, yes.up))
```

With the new data frame we can create a visualization that includes the confidence intervals. The code is similar to the previous _ggplot_ code used, but now with the addition of the _geom\_errorbar()_ function. The _geom\_errorbar()_ function requires arguments to use the lower and upper bound values for the confidence intervals:

```{r prop10, echo=TRUE}
ggplot(df, aes(x=answer, y=glbcc)) +
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=lower, ymax=upper))
```

### Two Populations

Research is often interested in differences between distinct populations. Using the _glbcc_ variable, we will review responses differentiated by gender.

```{r 2prop, echo=TRUE}
t.gcc.gend <- table(ds$glbcc, ds$f.gender)
t.gcc.gend
t.gcc.gend.p <- round(prop.table(t.gcc.gend, 2), 4)
t.gcc.gend.p

```

Respondent opinions on climate change can be examined on the difference of gender. This requires extracting the second row from the data set to create a table: 

```{r 2prop2, echo=TRUE}
yes.table <- t.gcc.gend.p[2,]
yes.table
```

To create a visualization, we will start with the mean proportion of support by gender:

```{r 2prop3, echo=TRUE}
men2 <- 0.5273
women2 <- 0.6013
```

Next we will calculate the standard error by gender. We will use the _subset()_ function to simplify the calculations:

```{r 2prop4, echo=TRUE}
male <- subset(ds, gender==1)
female <- subset(ds, gender==0)
```

Now the _describe()_ function used for the standard errors per gender:

```{r 2prop5, echo=TRUE}
men.se <- describe(male$glbcc)$se
women.se <- describe(female$glbcc)$se
```

The upper and lower bounds for the gender confidence intervals:

```{r 2prop6, echo=TRUE}
men.up <- men2 + 1.96*men.se
men.low <- men2 - 1.96*men.se
women.up <- women2 + 1.96*women.se
women.low <- women2 - 1.96*women.se
```

The confidence intervals used to create a data frame for the visualization:

```{r 2prop7, echo=TRUE}

df2 <- data.frame(gender = c("Men", "Women"), glbcc = c(men2,women2), lower = c(men.low,women.low),
                 upper = c(men.up, women.up))
```

Now the _ggplot_ visualization is constructed:

```{r 2prop8, echo=TRUE}
ggplot(df2, aes(x=gender, y=glbcc)) +
  geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=lower, ymax=upper))
```

Suppose we wondered whether women believe humans cause climate change more than men: this visualization provides only a partial answer. By the "eye test," the visualization appears to show that women have a higher value than men, and furthermore the confidence intervals do not overlap; however, the eye test alone is insufficient. An empirical test is required.

To start, we formulate the following hypotheses:  
$H_0$: there is no difference between genders  
$H_1$: there is a difference between genders  

We can use a two sample t-test to test these hypotheses. Using the different data sets created earlier for genders and the _glbcc_ variable we will find the 95% confidence interval, p-value, and point estimate.

```{r 2prop9, echo=TRUE}
t.test(male$glbcc, female$glbcc)
women2 - men2
```

The t-test yields a p-value < $\alpha$ = 0.05, thereby the null hypothesis is rejected to conclude there is a statistical significance in responses by gender. Further, the point estimate calculated as 0.074 informs us 7% more women than men believe humans cause climate change. __Note:__ The confidence interval tells us that, with 95% confidence, the difference between women and men is between 3% and 11%. Judgment is required to determine whether gender difference is substantive.

## Part II: Cross Tabulations

Another way to examine the difference of gender and beliefs about climate change is cross tabulation. Cross tabulations describe relationships between two variables. The basic building block of cross tabulations are tables, a skill acquired in previous labs.

For this section, we will use the _glbcc\_risk_ variable, that measures the level of risk respondents associate with climate change (on a scale of zero to ten). The range associated to this scale is simplified to zero to five:

For this section let's use a different climate change variable from our class data set: glbcc_risk. This variable measures the level of risk the repsondent associates with climate change, on a scale of zero to ten. That's a pretty wide scale, so let's brush up on our recoding and recode the variable to only go from zero to five:

```{r ct1, echo=TRUE}
ds$r.gccrsk <- recode(ds$glbcc_risk, "0:1=1; 2:3=2; 4:6=3; 7:8:=4; 9:10=5")
table(ds$r.gccrsk)
```

Next the variable is separated by gender using the _table()_ function. The dependent variable (_r.gccrsk_) is specified followed by the independent variable (_f.gender_):

```{r ct2, echo=TRUE}
gcc.table <- table(ds$r.gccrsk, ds$f.gender)
gcc.table
```

The _prop.table()_ function describes the relationship by proportions. We convert the proportion to percentage, then use the percentage by column and by row. The 2 and the 1 tell R to do so: 

```{r ct3, echo=TRUE}
round(prop.table(gcc.table, 2) * 100, 1)
```

There appears to be a difference in genders; however, as these differences are within a sample we cannot infer there is a difference in the population without an empirical test. We will use the Chi-Square test to empirically test whether there is a statistically significant difference in genders. The _chisq.test()_ function performs the Chi-Square test given a table:

```{r ct4, echo=TRUE}
chisq.test(gcc.table)
```

__Note:__ The _summary()_ function will provide additional information about this table, independent of a Chi-Square test.

```{r ct5, echo=TRUE}
summary(gcc.table)
```

Given the Chi-Square test p-value < $\alpha$ = 0.05, the null hypothesis is rejected such that there is a statistically significant difference between gender and perceived risk of climate change. Substantive difference is as important as statistical significance, and a variety of methods exist to test the strength of relationships. For the Chi-Square test, finding Cramer's Vs is the appropriate method. The _assocstats()_ function will return a variety of coefficients and numbers, including Cramer's V.


```{r ct6, echo=TRUE}
assocstats(gcc.table)
```

Cramer's V is a score ranging from 0 to 1, whereby 0 indicates a weak association and 1 indicates strong association. The Cramer's V score returned for the previous test is quite small, indicating a weak association.

Perhaps we are interested as gender as a control variable, with ideology as the independent variable. A new table for perceived risk of climate change, ideology (conservative, moderate, liberal), and gender is as follows:

```{r, ct7, echo=TRUE}
gcc.table2 <- table(ds$r.gccrsk, ds$f.ideology, ds$f.gender)
gcc.table2
```

Again, a Chi-Square test and Cramer's V will provide insight. To separate the genders, [,,1] is used for male and [,,2] is used for female.

For male:

```{r ct8, echo=TRUE}
chisq.test(gcc.table2[,,1])
assocstats(gcc.table2[,,1])
```

For female:

```{r ct9, echo=TRUE}
chisq.test(gcc.table2[,,2])
assocstats(gcc.table2[,,2])
```

Both chi-square tests return significant results, and both Cramer's V scores are about .4. The interpretation of this Cramer's V score is clearly stronger than the previous score; however, the score itself is not judged as a strong association.

### Other Coefficients

There are other coefficient scores that are appropriate to use in certain situations. The Phi coefficient is used with a 2x2 contingency table. The contingency coefficient, C, is used for square tables. Keep these different methods in mind when doing cross-tabulations and chi-square tests.

## Part III: Independent t-tests

This section elaborates on t-tests. So far we have emphasized t-tests, as the Student's t distribution can be used when n < 30, and when $\sigma$ is unknown. The rule of thumb is to use Student's t distribution in these two instances, and the normal distributions for all other cases; however, the Student's t distribution begins to approximate the normal distribution with high n sizes, so t-tests are applicable in most instances.

When using t-tests for two populations, you need to first decide if you should use an independent t-test or a paired t-test. An independent t-test is used when the two groups are independent from each other. A paired t-test is used for paired or connected groups. For the class data set the independent t-tests is appropriate. For an independent t-test, the variance between groups must be unequal.

Let's examine if there is a difference between the risk associated with climate change for Democrats and Republicans in our survey. In order to test only Democrats and Republicans, we need to recode our factored party variable to only include Democrats and Republicans:

```{r ind, echo=TRUE}
ds$f.part <- recode(ds$f.party.2, "'Dem'='Dem'; 'Rep'='Rep'; else=NA")
table(ds$f.part)
```

First we will compare variances for Democrats and Republicans on their risk perception of climate change. First we compare the standard deviations and standard errors:

```{r ind2, echo=TRUE}
by(ds$glbcc_risk, ds$f.part, describe)
```

The Levene test is used to test if the difference in variances is statistically significant. Similar to previously discussed hypotheses, the Levene tests the following hypotheses:

$H_0$: variances are equal  
$H_1$: variances are not equal  

```{r ind3, echo=TRUE}
leveneTest(ds$glbcc_risk, ds$f.part)
```

Given the p-value < $\alpha$ = 0.05, we reject the null hypothesis such that there is a statistically significant difference in variances. With this result we can perform an independent t-test for two populations. The framework for forming hypotheses is as follows:

$H_0$: the two populations are indifferent; "there is no difference in perceived risk of climate change between democrats and republicans"
$H_1$: the two populations are different; "there is a difference in perceived risk of climate change between democrats and republicans"

```{r ind4, echo=TRUE}
t.test(ds$glbcc_risk ~ ds$f.part, var.equal = FALSE) # var.equal=FALSE is default, you don't need to include it.
```

Given the p-value < $\alpha$ = 0.05, we reject the null hypothesis such that there is a statistically significant difference in perceived risk of climate change between democrats and republicans.

The previous test is an example of a two-tailed test, which lacks directionality (greater than, less than). In contrast, a one-tailed t-test tests hypotheses that include direction. To perform a one-tailed t-test, we include the command alt="greater" inside the _t.test()_ function:

```{r ind5, echo=TRUE}
t.test(ds$glbcc_risk ~ ds$f.part, alt="greater")
```

### Other Independent Sample Tests

Not all research leads to testing two populations. For example, consider whether a difference exists in perceived risk of climate change among democrats, republicans, and independents. Further, if there are statistically significant differences, how could ideologies be ranked? Unfortunately, performing pairwise t-tests on the possible combinations is inadequate, due to the "family-wise error rate" associated to the p-value. The _pairwise.t.test()_ function employs the family-wise correction method (by default, Holm-Bonferroni method) to correct the p-value.

Like traditional independent sample tests involving two samples, the variances must be unequal:

```{r hsd, echo=TRUE}
leveneTest(ds$glbcc_risk~ds$f.party.2)
```

Given that the p-value < $\alpha$ = 0.05, we reject the null hypothesis such that there is a difference in variances. The _pairwise.t.test()_ function can perform the pairwise test, using the _f.party_2_ variable that was factored for democrats, republicans, and independents:

```{r pairwise, echo=TRUE}
pairwise.t.test(ds$glbcc_risk, ds$f.party.2, pool.sd=FALSE)
```

The output of the _pairwise.t.test()_ function is read as a table, whereby each value is associated to the pairwise comparison.

An alternative, multiple comparisons test, is the Tukey Honest Significance Difference test ("Tukey's test"), that is commonly used with Analysis of Variance (ANOVA). In short, Tukey's test is used to find means that are significantly difference between multiple samples. Tukey's test requires using the _aov()_ function to perform ANOVA, as follows:

```{r hsd2, echo=TRUE}
TukeyHSD(aov(ds$glbcc_risk~ds$f.party.2))
```

The p-value < $\alpha$ = 0.05 between each pair. 

## Part IV: Paired t-test

Paired t-tests are appropriate for data that are not independent. Consider the need to compare data from the same population for different points in time, such as semester exams for the same students in a class.

The teacher wants to examine if there is a difference in the students' performances between exams one and two. The following hypothetical data frame could represent the students and their performance:

```{r paired, echo=TRUE}
Student <- c("st1", "st2", "st3", "st4", "st5", "st6", "st7", "st8", "st9", "st10")
Exam1 <- c(99, 98, 67, 68, 70, 71, 72, 88, 75, 83)
Exam2 <- c(94, 93, 62, 63, 65, 66, 67, 83, 70, 76) 
exam.ds <- data.frame(Student, Exam1, Exam2)
exam.ds
```

The _exam.ds_ data frame consists of three vectors: the student, exam one, and exam two.

First check the variance between the two groups:

```{r paired2, echo=TRUE}
var.test(exam.ds$Exam1, exam.ds$Exam2)

```

Given the p-value > $\alpha$ = 0.05, the null hypothesis is not rejected such that there is no statistically significant difference in variances.  
  
Next, we define our hypotheses for the paired test:  
$H_0$: there is no difference between exams one and two for students  
$H_1$: there is a difference between exams one and two for students

```{r paired3, echo=TRUE}
t.test(exam.ds$Exam1, exam.ds$Exam2, paired = TRUE, var.equal = TRUE)
```

Given the p-value < $\alpha$ = 0.05, the null hypothesis is rejected such that there is a statistically significant difference in means. Next, to determine directionality, the _alt="greater"_ argument is included in the _t.test()_ function. Additionally, the hypotheses are modified as follows:
$H_0$: there is no difference between exams one and two for students  
$H_1$: exams one performance is greater than exam two performance for students

```{r paired4, echo=TRUE}
t.test(exam.ds$Exam1, exam.ds$Exam2, paired = TRUE, var.equal = TRUE, alt = "greater")
```

Given the p-value < $\alpha$ = 0.05, the null hypothesis is rejected.

## Part V: Visualizing Differences in Means

Visualization of data is essential to interpreting and communicating difference in means. To demonstrate, we will use _ggplot2_ to visualize the difference in exam scores used with the paired t-tests.

First, we consider the difference of means with confidence intervals. We start by calculating the means for each exam:

```{r vis, echo=TRUE}
exam1 <- mean(exam.ds$Exam1, na.rm = T)
exam2 <- mean(exam.ds$Exam2, na.rm = T)

```

Then, the standard errors:

```{r vis2, echo=TRUE}
exam1.se <- describe(exam.ds$Exam1)$se
exam2.se <- describe(exam.ds$Exam2)$se
```

Lastly, the bounds for the confidence intervals. The 1.96 z-score is used for 95% confidence:

```{r vis3, echo=TRUE}
exam1up <- exam1 + exam1.se*1.96
exam1low <- exam1 - exam1.se*1.96
exam2up <- exam2 + exam2.se*1.96
exam2low <- exam2 - exam2.se*1.96
```

Next, a data frame is constructed with the previous information in respective vectors:

```{r vis4, echo=TRUE}
test <- c("Exam1", "Exam2")
scores <- c(exam1, exam2)
upper <- c(exam1up, exam2up)
lower <- c(exam1low, exam2low)
examdf <- data.frame(test, scores, upper, lower)
```

Now, for the visualization. Instead of a bar plot, we will create a graph consisting of a point for the means for each exam, and the confidence intervals. In additional, we will add color and labels. These arguments are available for other data sets and visualizations using _ggplot2_:

```{r vis5, echo = TRUE}
ggplot(examdf, aes(x=test, y=scores)) + # building the basic aesthetic
  geom_point(size=3, shape=19, col = "dodgerblue3") + # telling R to place points, the shape and color as well.
  geom_errorbar(aes(ymin=lower, ymax=upper), width=.1, col="dodgerblue3") + # making error bars based on the confidence intervals
  ylim(10,100) + # Setting the y axis
  ggtitle("Exam Scores") + # Main title
  xlab("Exams") + # Name for x axis
  ylab("Scores") # Name for y axis
```

Following the basic steps above will help you make attractive visualizations for different needs.

Suppose the teacher wanted a visualization that plots each students' test scores between the two exams for easy comparison. A grouped bar plot is a simple approach to accomplish this.

This requires a new data frame with vectors for exams, students, and scores:

```{r vis6, echo=TRUE}
Exam <- rep(c("Exam1", "Exam2"), each = 10) # Repeats "Exam 1" 10 times and then "Exam 2" 10 times
student <- rep(c("st1", "st2", "st3", "st4", "st5", "st6", "st7", "st8", "st9", "st10"),2) # Repeats the 10 student names 2 times
scores <- c(99, 98, 67, 68, 70, 71, 72, 88, 75, 83, 94, 93, 62, 63, 65, 66, 67, 83, 70, 76) # Lists the 10 Exam 1 scores and then the 10 exam 2 scores. 
exam.com <- data.frame(Exam, student, scores) # Creates the data frame
```

The new data frame pairs the exams with the students and the respective score:

```{r vis7, echo=TRUE}
exam.com
```

The grouped bar plot is constructed similar to a bar plot, except that the visualization is based on the exam and uses the _position.dodge()_ function to place bars near each other: 

```{r vis8, echo=TRUE}

ggplot(exam.com, aes(x=student, y=scores, fill=Exam)) +
  geom_bar(stat="identity", position = position_dodge())
```