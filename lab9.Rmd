---
title: 'Lab Nine: Categorical Explanatory Variables, Dummy Variables, and Interactions'
author:
 - Alex Davis
 - Cody Adams
output: pdf_document
---

This lab focuses on ways in which we use and understand categorical independent variables. So far the independent variables we have worked with have been interval or ordinal data. When working with categorical data, there are different approaches and techniques of interpretation. The following packages are required for this lab: 

1. ggplot2
2. psych
3. memisc
4. stargazer
5. gridExtra
6. interplot

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(psych)
library(car)
library(memisc)
library(stargazer)
library(gridExtra)
library(interplot)
options(scipen = 999)
ds <- read.csv("https://github.com/ripberjt/qrmlabs/raw/master/Class%20Data%20Set%20Factored.csv")
```

## Part I: Dummy Variables

We often have situations in the social sciences that require constructing models to include qualitative variables. To facilitate this, we employ dichotomous dummy variables to make the model function via 0s and 1s. In the presence of a category of interest the value is 1 and in the absence the value is 0.

To demonstrate dummy variables in models we will look to the class data set. The gender variable is coded as a 0 for women and 1 for men. This makes it a dummy variable for men, with women as the referent group. If we wanted to construct a model that looked at how certainty of climate change varied by gender, ideology, education, income, and age, our model would look like this:

$$Y_i=\alpha + \beta_{ideol} + \beta_{educ} + \beta_{inc} + \beta_{age} + \beta_{gend} + \epsilon_i$$
Where _B_gend_ is a binary indicator of gender, 0 for female and 1 for male. This means that when gender is female, gender equals 0.

Pull the data, omit missing variables, and look at the gender variable we are going to use:

```{r dum, echo=TRUE}
ds.sub <- subset(ds, select = c("ideol", "education", "income", "age", "gender", "f.gender", "glbcc_cert", "f.party", "glbcc_risk", "glbwrm_risk_fed_mgmt"))
ds.sub <- na.omit(ds.sub)
table(ds.sub$f.gender)
```

__Note:__ The factored gender variable lists men as 0 and women as 1. If you look at a table of the non-factored version, it shows the opposite. This is because R reads factored variables in alphabetical order. If we wanted to change the order of the factored variable:

```{r dum2, echo=TRUE}
ds.sub$f.gender <- factor(ds.sub$gender, levels = c(0,1), labels=c("Women", "Men"))
table(ds.sub$f.gender)
table(ds.sub$gender)
```

When working with a binary categorical explanatory variable (like the gender variable), you can use the numeric version of the variable. However, when working with categorical variables with more than two categories, it is often easier to use the factored version of the variable, for reasons we will get into shortly. We will use the factored gender variable in our model:

```{r dum3, echo=TRUE}
lm1 <- lm(glbcc_cert ~ ideol + education + income + age + f.gender, data=ds.sub)
summary(lm1)
```

Relying on our understanding from previous labs, we know that ideology and education have an effect on someone's certainty of climate change; however, now look at the role that gender plays. We used the factored version of gender in the model, so we need to interpret the results as such. The summary table says "f.genderMen", which means the variable is a dummy variable for men, with the referent category being women. The coefficient is interpreted as: the difference in in dependent variable from the referent category to the dummy category. In this case, the coefficient is statistically significant. To interpret it, we say that men are on average .406 units more convinced of climate change, on a scale of 0 to 10, all else held constant. The rest of the coefficients are interpreted as they have been in the past. But now you likely have a more accurate model, since you are "controlling" for gender. 

Visualizing the model should likely this more clear. If we want to visualize the relationship between ideology and climate change risk in our model __by gender__, we go about it in a similar way to previous visualizations. To separate men and women, you can use _group=DummyVariable_, to separate the two groups. Unfortunately, this does not give a way to distinguish between them. You can also use _color=DummyVariable_ to separate the groups, assign colors, and include a legend. 

```{r dum4, echo=TRUE}
ggplot(lm1, aes(x=ideol, y=glbcc_cert, color=f.gender)) +
  geom_smooth(aes(ideol, glbcc_cert, fill=f.gender), method = "lm", se=FALSE)
```

We turned off the confidence intervals to emphasize that you can think of the effect of dummy variables as a change in the value of the intercept. In this case our dummy variable for men is about 0.41, and you will notice that the line for men looks about that much above the women line. 

### Multiple Dummy Variables

Sometimes multiple dummy variables are necessary in models. This is the case when you need to include categorical variables with greater than two options, such as ideology (e.g., Republican, Democrat, Independent, Other). When working with these categorical variables, you need to select a referent group. Sometimes this decision is driven by the theory and or by convenience. R will automatically select a referent group if nothing is supplied. When using categorical variables with multiple options, the model will consist of multiple dummy variables for each of the groups (minus the referent group). You will always have one less dummy variable than the number of options. For example, for Republican, Democrat, Independent, and Other as the options, with Republican as the referent group you will have 3 dummy variables.

As an example using political party as a dummy variable. Start by looking at a table of the factored party variable:

```{r dum5, echo=TRUE}
table(ds.sub$f.party)
```

__Note:__ Democrat is listed first, therefore it is the referent category. Further, as a model there would exist coefficients and dummy variables for each of the political parties sans Democrat. R reads ideology as a factored variable and treats every party option as an independent dummy variable with Democrats as the referent category. Let's create a model based on the model we used earlier, but include the factored party variable as an independent variable. Due to potential multicollinearity issues, let's omit the ideology variable from the model. To make calculations simpler, we're going to use the non-factored version of gender. Since its a binary group, this will not change any of the coefficients:

```{r dum6, echo=TRUE}
lm2 <- lm(glbcc_cert ~ f.party  +education + income + age + gender, data=ds.sub)
summary(lm2)
```

We can see our model suggests that Independents and Republicans are, on average, less certain about climate change. The coefficient for Other is not significant, which makes sense given Other could indicate a panoply of political parties spanning the ideological spectrum. 

Now we will visualize this model. Dummy variables are similar to performing t-tests, but with statistical controls. First we  predict values based on party affiliation using the _predict()_ function for R to return predicted climate change certainty values based on political party, holding each other variable constant. We assign it to a data frame object named _values_. We also generate standard error values for each of the estimates:

```{r dum7, echo=TRUE}
values <- predict(lm2, newdata =  data.frame((f.party=c("Dem", "Ind", "Rep", "Other")), education=mean(ds.sub$education), income = mean(ds.sub$ideol), age=mean(ds.sub$age),
                                   gender = mean(ds.sub$gender)), se.fit = T)
values
```

In the next code chunks we construct a data frame that contains the following vectors:

1. Names of the parties.
2. Estimated values.
3. Upper confidence interval estimates.
4. Lower confidence interval estimates.

Doing so will provide an intuitive way behind the visualization. 

First the names:

```{r dum8, echo=TRUE}
party <- c("Democrat", "Independent", "Republican", "Other")
party
```

Now construct a vector with the point estimates. We name it _cert_ since we are measuring climate change certainty. The order of our party name vector was determined by the order that we predicted the estimated values:

```{r dum9, echo=TRUE}
cert <- values$fit
cert
```

Next we calculate the upper limit of the confidence interval:

```{r dum10, echo=TRUE}
upper <- cert + 1.96*values$se.fit
upper
```

Now do the same for the lower limit: 

```{r dum11, echo=TRUE}
lower <- cert - 1.96*values$se.fit
lower
```

Now, combine all the vectors into a data frame:

```{r dum12, echo=TRUE}
df <- data.frame(party, cert, upper, lower)
```

With the data frame constructed, next build the visualization. Our x-axis are party and the y-axis is climate change certainty. We'll use _geom_point()_ and _geom_errorbar_ to build the point estimates and confidence intervals:

```{r dum13, echo=TRUE}
ggplot(df, aes(x=party, y=cert)) +
  geom_point() +
  geom_errorbar(ymin=lower, ymax=upper, width=.1) +
  ylim(4,8) +
  ggtitle("Climate Change Certainty by Political Party") +
  ylab("Climate Change Certainty") +
  xlab("Political Party")
```

Perhaps you noticed that our model suggests that gender also plays a role. Next we are going to breakdown the relationship by party and gender simultaneous, by creating different predictions for each gender within each party. We create a new model including the factored gender variable:

```{r dum14, echo=TRUE}
lm3 <- lm(glbcc_cert ~ f.party  +education + income + age + f.gender, data=ds.sub)

```

The difference between the models is that the factored gender variable is used, which does not change any of the results. Now we follow a similar process in constructing the graphic, except we predict different values for men and women, and build vectors and confidence intervals separately before combining them.

First predict values. We do everything the same except this time we indicate a gender and not hold it constant:

```{r dum15, echo=TRUE}
men  <- predict(lm3, newdata =  data.frame((f.party=c("Dem", "Ind", "Other", "Rep")), education=mean(ds.sub$education), income = mean(ds.sub$ideol), age=mean(ds.sub$age),
                                                        f.gender = "Men"), se.fit = T)
women  <- predict(lm3, newdata =  data.frame((f.party=c("Dem", "Ind", "Other", "Rep")), education=mean(ds.sub$education), income = mean(ds.sub$ideol), age=mean(ds.sub$age),
                                                      f.gender = "Women"), se.fit = T)
```

Now create the party vector. This time we need R to repeat the order of the parties:

```{r dum16, echo=TRUE}
party2 <- rep(c("Dem", "Ind", "Other", "Rep"),2)
```

The climate change certainty values for men and women separately:

```{r dum17, echo=TRUE}
m.cert <- men$fit
w.cert <- women$fit
```

Combine the two values into one vector:

```{r dum18, echo=TRUE}
cert2 <- c(m.cert, w.cert)
```

Ceate the upper and lower confidence interval limits for men and women, then combine into two vectors:

```{r dum19, echo=TRUE}
m.up <- m.cert + 1.96*men$se.fit
m.low <- m.cert - 1.96*men$se.fit
w.up <- w.cert + 1.96*women$se.fit
w.low <- w.cert - 1.96*women$se.fit
up <- c(m.up, w.up)
low <- c(m.low, w.low)
```

Create a gender vector. It needs to repeat men and women four times:

```{r dum20, echo=TRUE}
gend <- rep(c("Men", "Women"), each=4)
```

Assign each vector to a data frame:

```{r dum21, echo=TRUE}
df2 <- data.frame(party2, gend, cert2, up, low)
df2
```

Build the visualization:

```{r dum22, echo=TRUE}
ggplot(df2, aes(x=party2, y=cert2, fill=gend)) +
  geom_bar(stat = "identity", position = position_dodge())

```

It appears that there might be a difference in climate change risk of the political parties by gender. If we were to test how political beliefs vary as a function of gender and are related to opinions about climate change certainty, we would need to explore interaction terms.

## Part II: Interactions

Interactions occur when the effect of one x is dependent on the value of another within a model. Previously, the value at any point of x were the same across all levels of another in predicting y. To demonstrate an interaction effect we will explore the interaction of gender and ideology on climate change certainty. We include the other predictors and specify this model: 

$$y_i=\beta_0 + \beta_1*(ideol) + \beta_2*(gender) + \beta_3*(ideol*gend) + \beta_4*(educ) + \beta_5*(inc) + \beta_6*(age) + \varepsilon_i$$

where gender is a binary indicator of men (1) or women (0). To specify this model in R:

```{r int, echo=TRUE}
lm3 <- lm(glbcc_cert ~ ideol*gender + education + income + age , data=ds.sub)
summary(lm3)
```

__Note:__ The formula includes ideology and gender interaction but does not specify the variables individually. R interprets the interaction and includes the separate variable terms for you. To interpret the results, notice that the _ideol:gender_ interaction coefficient is not statistically significant.

Let's review a new model looking at climate change risk instead of certainty. The independent variables, and interaction, remain the same:

```{r int2, echo=TRUE}
lm4 <- lm(glbcc_risk ~ ideol*f.gender + education + income + age , data=ds.sub)
summary(lm4)
```

As would be expected, ideology, education and income also exert statistically significant influence. Further, the interaction of ideology and gender is statistically significant. To interpret these results, we would say that there is an interaction (ideology effects climate change risk as a function of gender). We also know that the slope of the lines is negative. Often times the most intuitive way to understand interactions is to make predictions and visualize them.

Visualizing an interaction effect when the interaction term is binary is rather simple. There are two possible lines, when z=0 and when z=1, in this case when the gender is female or male. This makes the visualizing process similar to the first visualization, with the dummy variable:

```{r int3, echo=TRUE}
ggplot(lm4, aes(x=ideol, y=glbcc_risk, color=f.gender)) +
  geom_smooth(aes(ideol, glbcc_risk, fill=f.gender), method = "lm")

```

Notice how the slopes are different for men and women. The slope is steeper for men, suggesting that there is more of an interaction for men. Let's make some predictions:

First men:

```{r int4, echo=TRUE}
men.p <- predict(lm4, newdata = data.frame(ideol=seq(1:7), f.gender="Men", education=mean(ds.sub$education),
                                           income=mean(ds.sub$income), age=mean(ds.sub$age)), se.fit = T)
men.p

```

Now women:

```{r int5, echo=TRUE}
women.p <- predict(lm4, newdata = data.frame(ideol=seq(1:7), f.gender="Women", education=mean(ds.sub$education),
                                           income=mean(ds.sub$income), age=mean(ds.sub$age)), se.fit = T)
women.p
```

The difference between the first predicted value and the last is called the "first difference." We can tell that the first difference is larger for men. They have a higher first value and a higher last value.

### Interactions with Two Non-binary Variables

Theory and hypotheses often dictate the need to include an interaction between two variables when neither are binary. This makes the interpretation of interaction coefficients difficult, but nonetheless the process is the same. Suppose you want to explore people's attitudes about the role of federal government in climate change management. We can theorize that two primary predictors of these attitudes are ideology and climate change risk. Conservatives tend  to oppose federal government intervention and someone more concerned about climate change should likely support the attitudes about the role of federal government and perceived risk of climate change will be different among liberals and conservatives. We could further theorize that the relationship federal climate change management and climate change risk will be positive regardless of group, with individuals perceiving greater risk from climate change supporting more government management, but that relationship will be weaker for conservatives. We will specify the following hypothesis:

The relationship between perceived climate change risk and support for federal government management of climate change will be positive, but conditional on ideology. The relationship will be more pronounced for liberals and less pronounced for conservatives. 

First take a look at the federal climate change management variable:

```{r int7, echo=TRUE}
describe(ds.sub$glbwrm_risk_fed_mgmt)
```

We see that it is an ordinal variable ranging from 0 (not involved) to 10 (very involved).

Now we should specify the model, including appropriate controls:

```{r int8, echo=TRUE}
lm5 <- lm(glbwrm_risk_fed_mgmt ~ ideol*glbcc_risk + education + gender + income + age, data=ds.sub)
summary(lm5)
```

Right from the start we see that ideology and climate change risk both play significant roles. These coefficients are both statistically significant and substantive. A one unit change in either of the variables corresponds with more than a half point change in opinions about federal climate change management. Education and income also play roles, and notice that the interaction is significant. There is not a lot of intuitive interpretation we can gather from the coefficient alone; however, we see that it is very small, .026, and will likely not alter the slopes much. The best way to understand an interaction of two non-binary variables is to make predictions and visualize. We start with predictions.

First predict values of y for liberals:

```{r int9, echo=TRUE}
lib <- predict(lm5,newdata=data.frame(ideol=(1), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)

```

Now conservatives:

```{r int10, echo=TRUE}
con <- predict(lm5,newdata=data.frame(ideol=(7), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
```

Now compare, starting with liberals:

Liberals:
```{r int11, echo=TRUE}
lib$fit
```

Conservatives:

```{r int12, echo=TRUE}
con$fit

```

Find the first difference of each:

Liberals: 
```{r int13, echo=TRUE}
lib$fit[10] - lib$fit[1]
```

Conservatives:

```{r int14, echo=TRUE}
con$fit[10] - con$fit[1]

```

There is a greater first difference for conservatives. This combined with a significant interaction coefficient that is positive, we can start to see that perhaps the slopes of the lines are steeper for conservatives. Let's build a visualization that includes a prediction line for every ideology level. To do so we need to:

1. Generate predictions for every ideology score.
2. Put those predictions in data frames.
3. Visualize each individual line on a single plot.

Start with an ideology of 1 and then go to 7:

```{r int15, echo=TRUE}
id1 <-predict(lm5,newdata=data.frame(ideol=(1), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
id2 <- predict(lm5,newdata=data.frame(ideol=(2), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
id3 <- predict(lm5,newdata=data.frame(ideol=(3), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
id4 <- predict(lm5,newdata=data.frame(ideol=(4), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
id5 <- predict(lm5,newdata=data.frame(ideol=(5), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
id6 <- predict(lm5,newdata=data.frame(ideol=(6), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
id7 <- predict(lm5,newdata=data.frame(ideol=(7), gender=mean(ds.sub$gender), education=mean(ds.sub$education),
                                     income=mean(ds.sub$income), age=mean(ds.sub$age), glbcc_risk=seq(1,10,1)), se.fit = T)
```

Now put all the predicted values into their own data frames:

```{r int16, echo=TRUE}
p1 <- data.frame(glbcc_risk=1:10, id1)
p2 <- data.frame(glbcc_risk=1:10, id2)
p3 <- data.frame(glbcc_risk=1:10, id3)
p4 <- data.frame(glbcc_risk=1:10, id4)
p5 <- data.frame(glbcc_risk=1:10, id5)
p6 <- data.frame(glbcc_risk=1:10, id6)
p7 <- data.frame(glbcc_risk=1:10, id7)
```

Next we are going to create a color scale. This will help the visualization because we are visualizing multiple lines. Create a scale with 7 values, one for each ideology score, that goes from blue (liberal) to red (conservative):

```{r int17, echo=TRUE}
col_scale<-colorRampPalette(c("#0200bd50","#FF000050"))(7)
```

Now build the visualization. We have been using _geom_smooth()_, but this time we will use _geom_line()_, because we already predicted the values we want to plot. Let's make this a complete visualization, including axis labels, and a title.

```{r int18, echo=TRUE}
ggplot() +
  geom_line(data=p1, aes(glbcc_risk, fit), size=2, color= col_scale[1]) +
  geom_line(data=p2, aes(glbcc_risk, fit), size=2, color= col_scale[2]) +
  geom_line(data=p3, aes(glbcc_risk, fit), size=2, color= col_scale[3]) +
  geom_line(data=p4, aes(glbcc_risk, fit), size=2, color= col_scale[4]) +
  geom_line(data=p5, aes(glbcc_risk, fit), size=2, color= col_scale[5]) +
  geom_line(data=p6, aes(glbcc_risk, fit), size=2, color= col_scale[6]) +
  geom_line(data=p7, aes(glbcc_risk, fit), size=2, color= col_scale[7]) +
  ggtitle("Climate Change Risk and Federal Management by Ideology") +
  xlab("Climate Change Risk") +
  ylab("Level of Federal Management") +
  theme_bw()

```

Consider everything we've found so far. The positive interaction coefficient, the larger first difference for conservatives, and now this visualization. It is quite clear that the relationship between climate change risk and preferred level of federal climate change management is appears to be stronger for conservatives. The slopes of the lines become steeper as the ideology score increases. This was not what we hypothesized, and therefore we cannot reject the null hypothesis.

## Part III: Releveling Variables

As mentioned earlier, R can sometimes re-order a variable. This is the case the for factored variables, when R automatically reads them alphabetically. Sometimes you need to relevel a variable by necessity and sometimes by preference. Let's look at the factored party variable:

```{r rel, echo=TRUE}
table(ds$f.party)
```

Notice the variable is in alphabetical order. If we included this variable in our model, R would read the Democrat category as the referent group. Perhaps you wanted Republicans to be the referent group. There are a couple ways to do this. The first way would be to refactor the numeric version of the variable. First look at the unfactored version:

```{r rel2, echo=TRUE}
table(ds$party)
```

We compare this to the factored version and extrapolate that the 2 value indicates Republicans. So when factoring the variable we will list 2 first:

```{r rel3, echo=TRUE}
ds$f.party2 <- factor(ds$party, levels = c(2,1,3,4), labels = c("Rep", "Dem", "Ind", "Other"))
table(ds$f.party2)
```

This is one way to go about it. This way has its merits, such as wanting to re-order every level of the variable, not just the referent group. But there is another way, one that changes the referent group one. Using the _relevel()_ function, and indicating the referent group with the _ref=_ argument. Let's do so, and make Republicans the referent group:

```{r rel4, echo=TRUE}
ds$f.party3 <- relevel(ds$f.party, ref = "Rep")
table(ds$f.party3)
```

## Part IV: Interaction Plots

Our exploration of interactions plotted estimated Y values as X varies as a function of Z. Specifically, we looked at the relationship between climate change management and climate change risk as a function of ideology. We plotted prediction lines for every level of ideology. However, there is another way we can explore interaction effects. Using the _interplot()_ function, we calculate and visualize estimates of the coefficient of an independent variable in an interaction. Meaning, instead of looking at predicted values of a dependent variable, we are looking at the estimated effect of an independent variable on a dependent variable in a model that includes a two-way interaction. 

To create an interaction plot for our earlier model we need to specify the two variables in the interaction. The first variable we specify is the variable of interest, the one for which we want estimated coefficients. The second is the other variable in the interaction.

```{r ip, echo=TRUE}
interplot(lm5, var1="glbcc_risk", var2 = "ideol")
```

This plot graphs the estimated coefficient of climate change risk by ideology score. The estimated effect of climate change risk on federal climate change management appears stronger for more conservative individuals. 

Instead of plotting individual estimates, we could plot a line that also visualizes the relationship. To do this we would specify _hist=T_, which plots a histogram on the bottom and a line for the estimated coefficients. Let's add titles on this plot as well:

```{r ip2, echo=TRUE}
interplot(m=lm5, var1="glbcc_risk", var2="ideol", hist=T) +
  ggtitle("Estimated Coefficient of Climate Change Risk by Ideology") +
  theme_bw() +
  xlab("Ideology: Liberal to Conservative") +
  ylab("Climate Change Risk Coefficient")


```